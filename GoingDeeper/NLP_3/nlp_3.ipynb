{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5898f89",
   "metadata": {},
   "source": [
    "# 3-3. 단어 빈도를 이용한 벡터화 (2) Bag of Words 구현해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19f1c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "sentence = [\"John likes to watch movies. Mary likes movies too! Mary also likes to watch football games.\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fb789b",
   "metadata": {},
   "source": [
    "# 3-7. 단어 빈도를 이용한 벡터화 (6) TF-IDF 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cd07e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete\n"
     ]
    }
   ],
   "source": [
    "from math import log\n",
    "import pandas as pd\n",
    "print(\"complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3205bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\n",
    "  'John likes to watch movies and Mary likes movies too',\n",
    "  'James likes to watch TV',\n",
    "  'Mary also likes to watch football games',  \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e68ae59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어장의 크기 :  13\n",
      "['James', 'John', 'Mary', 'TV', 'also', 'and', 'football', 'games', 'likes', 'movies', 'to', 'too', 'watch']\n"
     ]
    }
   ],
   "source": [
    "vocab = list(set(w for doc in docs for w in doc.split()))\n",
    "vocab.sort()\n",
    "print(\"단어장의 크기 : \",len(vocab))\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03633993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = len(docs) #총 문서의 수 \n",
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a911b702",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf(t,d):\n",
    "    return d.count(t)\n",
    "\n",
    "def idf(t):\n",
    "    df = 0\n",
    "    for doc in docs:\n",
    "        df += t in doc\n",
    "    return log(N/(df+1)) +1\n",
    "\n",
    "def tfidf(t,d):\n",
    "    return tf(t,d) * idf(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc45aff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>James</th>\n",
       "      <th>John</th>\n",
       "      <th>Mary</th>\n",
       "      <th>TV</th>\n",
       "      <th>also</th>\n",
       "      <th>and</th>\n",
       "      <th>football</th>\n",
       "      <th>games</th>\n",
       "      <th>likes</th>\n",
       "      <th>movies</th>\n",
       "      <th>to</th>\n",
       "      <th>too</th>\n",
       "      <th>watch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   James  John  Mary  TV  also  and  football  games  likes  movies  to  too  \\\n",
       "0      0     1     1   0     0    1         0      0      2       2   2    1   \n",
       "1      1     0     0   1     0    0         0      0      1       0   1    0   \n",
       "2      0     0     1   0     1    0         1      1      1       0   1    0   \n",
       "\n",
       "   watch  \n",
       "0      1  \n",
       "1      1  \n",
       "2      1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = []\n",
    "for i in range(N):\n",
    "    result.append([]) #3개의 행을 만든다.\n",
    "    d = docs[i] #1번째 문장, 2번째 문장, 3번째 문장\n",
    "    for j in range(len(vocab)):\n",
    "        t = vocab[j]\n",
    "        \n",
    "        result[-1].append(tf(t,d))\n",
    "        \n",
    "tf_ = pd.DataFrame(result,columns=vocab)\n",
    "tf_\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a480c120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>James</th>\n",
       "      <td>1.405465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>John</th>\n",
       "      <td>1.405465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mary</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TV</th>\n",
       "      <td>1.405465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>also</th>\n",
       "      <td>1.405465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>1.405465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>football</th>\n",
       "      <td>1.405465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>games</th>\n",
       "      <td>1.405465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>likes</th>\n",
       "      <td>0.712318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movies</th>\n",
       "      <td>1.405465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>0.712318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>too</th>\n",
       "      <td>1.405465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>watch</th>\n",
       "      <td>0.712318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               IDF\n",
       "James     1.405465\n",
       "John      1.405465\n",
       "Mary      1.000000\n",
       "TV        1.405465\n",
       "also      1.405465\n",
       "and       1.405465\n",
       "football  1.405465\n",
       "games     1.405465\n",
       "likes     0.712318\n",
       "movies    1.405465\n",
       "to        0.712318\n",
       "too       1.405465\n",
       "watch     0.712318"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = []\n",
    "for j in range(len(vocab)):\n",
    "    t = vocab[j]\n",
    "    result.append(idf(t))\n",
    "    \n",
    "idf_ = pd.DataFrame(result,index=vocab,columns=[\"IDF\"])\n",
    "idf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32b88fba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>James</th>\n",
       "      <th>John</th>\n",
       "      <th>Mary</th>\n",
       "      <th>TV</th>\n",
       "      <th>also</th>\n",
       "      <th>and</th>\n",
       "      <th>football</th>\n",
       "      <th>games</th>\n",
       "      <th>likes</th>\n",
       "      <th>movies</th>\n",
       "      <th>to</th>\n",
       "      <th>too</th>\n",
       "      <th>watch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.405465</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.405465</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.424636</td>\n",
       "      <td>2.81093</td>\n",
       "      <td>1.424636</td>\n",
       "      <td>1.405465</td>\n",
       "      <td>0.712318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.405465</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.405465</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.712318</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.712318</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.712318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.405465</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.405465</td>\n",
       "      <td>1.405465</td>\n",
       "      <td>0.712318</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.712318</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.712318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      James      John  Mary        TV      also       and  football     games  \\\n",
       "0  0.000000  1.405465   1.0  0.000000  0.000000  1.405465  0.000000  0.000000   \n",
       "1  1.405465  0.000000   0.0  1.405465  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.000000  0.000000   1.0  0.000000  1.405465  0.000000  1.405465  1.405465   \n",
       "\n",
       "      likes   movies        to       too     watch  \n",
       "0  1.424636  2.81093  1.424636  1.405465  0.712318  \n",
       "1  0.712318  0.00000  0.712318  0.000000  0.712318  \n",
       "2  0.712318  0.00000  0.712318  0.000000  0.712318  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = []\n",
    "for i in range(N):\n",
    "    result.append([])\n",
    "    d = docs[i]\n",
    "    for j in range(len(vocab)):\n",
    "        t = vocab[j]\n",
    "        \n",
    "        result[-1].append(tfidf(t,d))\n",
    "        \n",
    "tfidf_ = pd.DataFrame(result,columns=vocab)\n",
    "tfidf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edc8a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사이킷런을 활용해보자\n",
    "#1. CountVectorizer을 이용하면 DTM을 만들 수 있다.\n",
    "#2. TfidfVectorizer을 이용하면 TF-IDF을 만들 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66bbee11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'john': 5, 'likes': 6, 'to': 9, 'watch': 12, 'movies': 8, 'and': 1, 'mary': 7, 'too': 10, 'james': 4, 'tv': 11, 'also': 0, 'football': 2, 'games': 3}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>also</th>\n",
       "      <th>and</th>\n",
       "      <th>football</th>\n",
       "      <th>games</th>\n",
       "      <th>james</th>\n",
       "      <th>john</th>\n",
       "      <th>likes</th>\n",
       "      <th>mary</th>\n",
       "      <th>movies</th>\n",
       "      <th>to</th>\n",
       "      <th>too</th>\n",
       "      <th>tv</th>\n",
       "      <th>watch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.321556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.321556</td>\n",
       "      <td>0.379832</td>\n",
       "      <td>0.244551</td>\n",
       "      <td>0.643111</td>\n",
       "      <td>0.189916</td>\n",
       "      <td>0.321556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.189916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.572929</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.338381</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.338381</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.572929</td>\n",
       "      <td>0.338381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.464997</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.464997</td>\n",
       "      <td>0.464997</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.274634</td>\n",
       "      <td>0.353642</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.274634</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.274634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       also       and  football     games     james      john     likes  \\\n",
       "0  0.000000  0.321556  0.000000  0.000000  0.000000  0.321556  0.379832   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.572929  0.000000  0.338381   \n",
       "2  0.464997  0.000000  0.464997  0.464997  0.000000  0.000000  0.274634   \n",
       "\n",
       "       mary    movies        to       too        tv     watch  \n",
       "0  0.244551  0.643111  0.189916  0.321556  0.000000  0.189916  \n",
       "1  0.000000  0.000000  0.338381  0.000000  0.572929  0.338381  \n",
       "2  0.353642  0.000000  0.274634  0.000000  0.000000  0.274634  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "corpus = [\n",
    "  'John likes to watch movies and Mary likes movies too',\n",
    "  'James likes to watch TV',\n",
    "  'Mary also likes to watch football games',  \n",
    "]\n",
    "\n",
    "tfidfv = TfidfVectorizer().fit(corpus)\n",
    "print(tfidfv.vocabulary_)\n",
    "vocab = list(tfidfv.vocabulary_.keys()) # 단어장을 리스트로 저장\n",
    "vocab.sort() # 단어장을 알파벳 순으로 정렬\n",
    "\n",
    "# TF-IDF 행렬에 단어장을 데이터프레임의 열로 지정하여 데이터프레임 생성\n",
    "tfidf_ = pd.DataFrame(tfidfv.transform(corpus).toarray(), columns = vocab)\n",
    "tfidf_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc75132",
   "metadata": {},
   "source": [
    "# 3-9. LSA와 LDA (2) LSA 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4d9bb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce3241a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/songye/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package wordnet to /Users/songye/nltk_data...\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/songye/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f091cd3f",
   "metadata": {},
   "source": [
    "### 데이터 다운로드 및 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8374b71c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./data/abcnews-date-text.csv', <http.client.HTTPMessage at 0x7fdcbf18cb90>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "csv_filename = './data/abcnews-date-text.csv'\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/franciscadias/data/master/abcnews-date-text.csv\", \n",
    "                           filename=csv_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b34e385f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1082168, 2)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(csv_filename)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "36d4a68f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publish_date</th>\n",
       "      <th>headline_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20030219</td>\n",
       "      <td>aba decides against community broadcasting lic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20030219</td>\n",
       "      <td>act fire witnesses must be aware of defamation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20030219</td>\n",
       "      <td>a g calls for infrastructure protection summit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20030219</td>\n",
       "      <td>air nz staff in aust strike for pay rise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20030219</td>\n",
       "      <td>air nz strike to affect australian travellers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   publish_date                                      headline_text\n",
       "0      20030219  aba decides against community broadcasting lic...\n",
       "1      20030219     act fire witnesses must be aware of defamation\n",
       "2      20030219     a g calls for infrastructure protection summit\n",
       "3      20030219           air nz staff in aust strike for pay rise\n",
       "4      20030219      air nz strike to affect australian travellers"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "387f0924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aba decides against community broadcasting lic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>act fire witnesses must be aware of defamation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a g calls for infrastructure protection summit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air nz staff in aust strike for pay rise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air nz strike to affect australian travellers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       headline_text\n",
       "0  aba decides against community broadcasting lic...\n",
       "1     act fire witnesses must be aware of defamation\n",
       "2     a g calls for infrastructure protection summit\n",
       "3           air nz staff in aust strike for pay rise\n",
       "4      air nz strike to affect australian travellers"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = data[['headline_text']].copy()\n",
    "text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e7d0dcc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "headline_text    1054983\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "125b387f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1054983, 1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.drop_duplicates(inplace=True)\n",
    "text.reset_index(drop=True,inplace=True)\n",
    "text.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162573e4",
   "metadata": {},
   "source": [
    "### 데이터 정제 및 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8f7df5b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[aba, decides, community, broadcasting, licence]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[act, fire, witnesses, must, aware, defamation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[g, calls, infrastructure, protection, summit]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[air, nz, staff, aust, strike, pay, rise]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[air, nz, strike, affect, australian, travellers]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       headline_text\n",
       "0   [aba, decides, community, broadcasting, licence]\n",
       "1    [act, fire, witnesses, must, aware, defamation]\n",
       "2     [g, calls, infrastructure, protection, summit]\n",
       "3          [air, nz, staff, aust, strike, pay, rise]\n",
       "4  [air, nz, strike, affect, australian, travellers]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text['headline_text'] = text.apply(lambda row: nltk.word_tokenize(row['headline_text']),axis=1)\n",
    "\n",
    "#불용어 제거\n",
    "stop_words = stopwords.words('english')\n",
    "text['headline_text'] = text['headline_text'].apply(lambda x: [word for word in x if word not in (stop_words)])\n",
    "\n",
    "text.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cee725c",
   "metadata": {},
   "source": [
    "#### 단어 정규화 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e764513e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     [aba, decide, community, broadcast, licence]\n",
      "1    [act, fire, witness, must, aware, defamation]\n",
      "2       [call, infrastructure, protection, summit]\n",
      "3            [air, staff, aust, strike, pay, rise]\n",
      "4    [air, strike, affect, australian, travellers]\n",
      "Name: headline_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "text['headline_text'] = text['headline_text'].apply(lambda x : [WordNetLemmatizer().lemmatize(word,pos='v') for word in x])\n",
    "\n",
    "text = text['headline_text'].apply(lambda x : [word for word in x if len(word) >2])\n",
    "print(text[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f859ca6b",
   "metadata": {},
   "source": [
    "### 역토큰화 및 DTM 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4163b481",
   "metadata": {},
   "outputs": [],
   "source": [
    "detokenized_doc = []\n",
    "for i in range(len(text)):\n",
    "    t = ' '.join(text[i])\n",
    "    detokenized_doc.append(t)\n",
    "    \n",
    "train_data = detokenized_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "30de9942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aba decide community broadcast licence',\n",
       " 'act fire witness must aware defamation',\n",
       " 'call infrastructure protection summit',\n",
       " 'air staff aust strike pay rise',\n",
       " 'air strike affect australian travellers']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bae3d3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_vectorizer = CountVectorizer(stop_words='english',max_features=5000)\n",
    "document_term_matrix = c_vectorizer.fit_transform(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a3434e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "행렬의 크기 :  (1054983, 5000)\n"
     ]
    }
   ],
   "source": [
    "print(\"행렬의 크기 : \",document_term_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7958abef",
   "metadata": {},
   "source": [
    "### scikit-learn TruncatedSVD 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "169a35fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.20415307e-02, -3.73270858e-03,  1.82724274e-02, ...,\n",
       "         4.23228377e-03, -3.03848091e-04,  1.82502076e-02],\n",
       "       [ 2.90462145e-02, -1.09333379e-02,  1.81627315e-02, ...,\n",
       "        -3.79688331e-03,  6.55757954e-03, -1.44432048e-03],\n",
       "       [ 5.03215593e-03, -2.03619153e-03,  9.74510468e-03, ...,\n",
       "        -2.15329756e-03, -1.96421012e-03,  3.62965374e-03],\n",
       "       ...,\n",
       "       [ 2.96578856e-02,  4.04752706e-03,  2.50394015e-02, ...,\n",
       "         3.14150834e-02, -1.04414762e-02,  1.85017100e-02],\n",
       "       [ 6.18357507e-02, -6.00603026e-03,  1.36524806e-01, ...,\n",
       "         9.75172609e-01, -7.17958964e-01, -3.38534760e-01],\n",
       "       [ 7.14795998e-02,  2.82027209e-02, -1.23578357e-04, ...,\n",
       "        -1.46585733e-02, -1.25636736e-02,  7.15685905e-02]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "n_topics = 10\n",
    "lsa_model = TruncatedSVD(n_components=n_topics)\n",
    "lsa_model.fit_transform(document_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2b9b36ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 5000)\n"
     ]
    }
   ],
   "source": [
    "print(lsa_model.components_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "25a40b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: [('police', 0.74636), ('man', 0.45349), ('charge', 0.21096), ('new', 0.14091), ('court', 0.11159)]\n",
      "Topic 2: [('man', 0.69427), ('charge', 0.30047), ('court', 0.16783), ('face', 0.1151), ('murder', 0.10639)]\n",
      "Topic 3: [('new', 0.83641), ('plan', 0.23656), ('say', 0.18266), ('govt', 0.11052), ('council', 0.11017)]\n",
      "Topic 4: [('say', 0.74064), ('plan', 0.3581), ('govt', 0.16477), ('council', 0.12527), ('urge', 0.0786)]\n",
      "Topic 5: [('plan', 0.73554), ('council', 0.17621), ('govt', 0.13826), ('urge', 0.08416), ('water', 0.06537)]\n",
      "Topic 6: [('govt', 0.55496), ('urge', 0.25133), ('court', 0.25105), ('fund', 0.21706), ('win', 0.1485)]\n",
      "Topic 7: [('charge', 0.51295), ('court', 0.46743), ('face', 0.33658), ('murder', 0.13411), ('plan', 0.11696)]\n",
      "Topic 8: [('win', 0.67062), ('kill', 0.24205), ('court', 0.22531), ('crash', 0.13642), ('council', 0.12895)]\n",
      "Topic 9: [('court', 0.55366), ('face', 0.18293), ('kill', 0.13586), ('accuse', 0.10315), ('crash', 0.07372)]\n",
      "Topic 10: [('council', 0.76479), ('charge', 0.1552), ('crash', 0.14746), ('health', 0.0851), ('kill', 0.08261)]\n"
     ]
    }
   ],
   "source": [
    "terms = c_vectorizer.get_feature_names_out()\n",
    "\n",
    "def get_topics(components,feature_names,n=5):\n",
    "    for idx,topic in enumerate(components):\n",
    "        print(\"Topic %d:\" % (idx+1), [(feature_names[i], topic[i].round(5)) for i in topic.argsort()[:-n - 1:-1]])\n",
    "        \n",
    "\n",
    "get_topics(lsa_model.components_,terms)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74669a46",
   "metadata": {},
   "source": [
    "# 3-11. LSA와 LDA (4) LDA 실습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5fc782",
   "metadata": {},
   "source": [
    "### TF-IDF 행렬 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ea63b0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1054983, 5000)\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english',max_features=5000)\n",
    "tf_idf_matrix = tfidf_vectorizer.fit_transform(train_data)\n",
    "\n",
    "print(tf_idf_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7347917e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2x5000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 8 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_matrix[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e54e11d",
   "metadata": {},
   "source": [
    "### scikit-learn LDA Model 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "44da9754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0335099 , 0.0335099 , 0.0335099 , ..., 0.17024867, 0.0335099 ,\n",
       "        0.0335099 ],\n",
       "       [0.03365631, 0.03365631, 0.03365631, ..., 0.03365631, 0.03365631,\n",
       "        0.03365631],\n",
       "       [0.25184095, 0.0366096 , 0.0366096 , ..., 0.0366096 , 0.0366096 ,\n",
       "        0.0366096 ],\n",
       "       ...,\n",
       "       [0.26687206, 0.02914502, 0.02914502, ..., 0.13007484, 0.02916018,\n",
       "        0.28739608],\n",
       "       [0.10378115, 0.02637829, 0.12325014, ..., 0.02637829, 0.02637829,\n",
       "        0.02637829],\n",
       "       [0.03376055, 0.03376055, 0.2255442 , ..., 0.03376055, 0.03376055,\n",
       "        0.03376055]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "lda_model = LatentDirichletAllocation(n_components=10,learning_method='online',random_state=777,max_iter=1)\n",
    "lda_model.fit_transform(tf_idf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "17bfa028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 5000)\n"
     ]
    }
   ],
   "source": [
    "print(lsa_model.components_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5c12d728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: [('australia', 9359.06334), ('sydney', 5854.97288), ('attack', 4784.76322), ('change', 4193.63035), ('year', 3924.88997)]\n",
      "Topic 2: [('government', 6344.07413), ('charge', 5947.12292), ('man', 4519.7974), ('state', 3658.16422), ('live', 3625.10473)]\n",
      "Topic 3: [('australian', 7666.65651), ('say', 7561.01807), ('police', 5513.22932), ('home', 4048.38409), ('report', 3796.04446)]\n",
      "Topic 4: [('melbourne', 5298.35047), ('south', 4844.59835), ('death', 4281.78433), ('china', 3214.44581), ('women', 3029.28443)]\n",
      "Topic 5: [('win', 5704.0914), ('canberra', 4322.0963), ('die', 4025.63057), ('open', 3771.65243), ('warn', 3577.47151)]\n",
      "Topic 6: [('court', 5246.3124), ('world', 4536.86331), ('country', 4166.34794), ('woman', 3983.97748), ('crash', 3793.50267)]\n",
      "Topic 7: [('election', 5418.5038), ('adelaide', 4864.95604), ('house', 4478.6135), ('school', 3966.82676), ('2016', 3955.11155)]\n",
      "Topic 8: [('trump', 8189.58575), ('new', 6625.2724), ('north', 3705.40987), ('rural', 3521.42659), ('donald', 3356.26657)]\n",
      "Topic 9: [('perth', 4552.8151), ('kill', 4093.61782), ('break', 2695.71958), ('budget', 2596.93268), ('children', 2586.01957)]\n",
      "Topic 10: [('queensland', 5552.68506), ('coast', 3825.32603), ('tasmanian', 3550.75997), ('shoot', 3185.71575), ('service', 2695.21462)]\n"
     ]
    }
   ],
   "source": [
    "terms = c_vectorizer.get_feature_names_out()\n",
    "\n",
    "def get_topics(components,feature_names,n=5):\n",
    "    for idx,topic in enumerate(components):\n",
    "        print(\"Topic %d:\" % (idx+1), [(feature_names[i], topic[i].round(5)) for i in topic.argsort()[:-n - 1:-1]])\n",
    "        \n",
    "\n",
    "get_topics(lda_model.components_,terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a08d81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b1c0692",
   "metadata": {},
   "source": [
    "# 5-2. 벡터화 실습: 원-핫 인코딩 구현해보기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2f5a05",
   "metadata": {},
   "source": [
    "### Step 1. 패키지 설치하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "829927d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from konlpy.tag import Okt\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3580307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'임금님 귀는 당나귀 귀! 임금님 귀는 당나귀 귀! 실컷~ 소리치고 나니 속이 확 뚫려 살 것 같았어.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"임금님 귀는 당나귀 귀! 임금님 귀는 당나귀 귀! 실컷~ 소리치고 나니 속이 확 뚫려 살 것 같았어.\"\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ac387a",
   "metadata": {},
   "source": [
    "### Step 2. 전처리 이야기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a58da28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임금님 귀는 당나귀 귀 임금님 귀는 당나귀 귀 실컷 소리치고 나니 속이 확 뚫려 살 것 같았어\n"
     ]
    }
   ],
   "source": [
    "reg = re.compile(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\")\n",
    "text = reg.sub(\"\", text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6732a842",
   "metadata": {},
   "source": [
    "### Step 3. 토큰화 이야기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "339f5830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['임금님', '귀', '는', '당나귀', '귀', '임금님', '귀', '는', '당나귀', '귀', '실컷', '소리', '치고', '나니', '속이', '확', '뚫려', '살', '것', '같았어']\n"
     ]
    }
   ],
   "source": [
    "okt = Okt()\n",
    "tokens = okt.morphs(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642c3f21",
   "metadata": {},
   "source": [
    "### Step 4. 단어장 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01e97f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'귀': 4, '임금님': 2, '는': 2, '당나귀': 2, '실컷': 1, '소리': 1, '치고': 1, '나니': 1, '속이': 1, '확': 1, '뚫려': 1, '살': 1, '것': 1, '같았어': 1})\n"
     ]
    }
   ],
   "source": [
    "vocab = Counter(tokens)\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "570e8bd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab['임금님']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d769a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('귀', 4), ('임금님', 2), ('는', 2), ('당나귀', 2), ('실컷', 1)]\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 5\n",
    "vocab = vocab.most_common(vocab_size)\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd35ca6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'귀': 1, '임금님': 2, '는': 3, '당나귀': 4, '실컷': 5}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx= {word[0]: index+1 for index,word in enumerate(vocab)}\n",
    "word2idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65620e43",
   "metadata": {},
   "source": [
    "### Step 5: 원-핫 벡터 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96b4db4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encoding(word,word2index):\n",
    "    one_hot_vector = [0] * (len(word2index)) #[0, 0, 0, 0, 0]\n",
    "    index = word2index[word] #index=2\n",
    "    one_hot_vector[index-1] = 1 #첫번째 인덱스 위치에 \n",
    "    return one_hot_vector\n",
    "print(\"completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2d800db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 0, 0]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encoding(\"임금님\",word2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb04ab46",
   "metadata": {},
   "source": [
    "### 케라스를 통한 원-핫 인코딩(one-hot encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81f2b0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8615fdd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['강아지', '고양이', '강아지'], ['애교', '고양이'], ['컴퓨터', '노트북']]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = [['강아지', '고양이', '강아지'],['애교', '고양이'], ['컴퓨터', '노트북']]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee5adc54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'강아지': 1, '고양이': 2, '애교': 3, '컴퓨터': 4, '노트북': 5}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#케라스 토크나이저는 주어진 텍스트로부터 단어장을 만들고 단어장의 각 단어에 고유한 정수를 맵핑해준다. \n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(text)\n",
    "t.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b40a210",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(t.word_index) +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "794c2f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 1, 4]]\n"
     ]
    }
   ],
   "source": [
    "sub_text = ['강아지','고양이','강아지','컴퓨터','바보']\n",
    "encoded = t.texts_to_sequences([sub_text])\n",
    "print(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3671649d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 1. 0. 0. 0. 0.]\n",
      "  [0. 0. 1. 0. 0. 0.]\n",
      "  [0. 1. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 1. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "one_hot = to_categorical(encoded,num_classes=vocab_size)\n",
    "print(one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df678475",
   "metadata": {},
   "source": [
    "# 5-3. 워드 임베딩"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cca1eaa",
   "metadata": {},
   "source": [
    "### 희소 벡터(Sparse Vector)의 문제점"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972206dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#이에 대한 대안으로 '기계가 단어장 크기보다 적은 차원의 밀집 벡터(dense vector)를 학습'하는 워드 임베딩(word embedding) 이 제안되었습니다. 이를 통해 얻는 밀집 벡터는 각 차원이 0과 1이 아닌 다양한 실숫값을 가지며, 이 밀집 벡터를 임베딩 벡터(embedding vector) 라고 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acc1fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#결론적으로 워드 임베딩에서 중요한 것은 두 가지 입니다.\n",
    "#한 단어를 길이가 비교적 짧은 밀집 벡터로 나타낸다.\n",
    "#그런데 이 밀집 벡터는 단어가 갖는 의미나 단어 간의 관계 등을 어떤 식으로든 내포하고 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28517e9c",
   "metadata": {},
   "source": [
    "# 5-5. Word2Vec (2) CBoW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fec1b66",
   "metadata": {},
   "source": [
    "# 5-7. Word2Vec (4) 영어 Word2Vec 실습과 OOV 문제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f05cea32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package abc to /Users/songye/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/abc.zip.\n",
      "[nltk_data] Downloading package punkt to /Users/songye/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('abc')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9e55d6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import abc\n",
    "corpus = abc.sents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e3499d11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['PM',\n",
       "  'denies',\n",
       "  'knowledge',\n",
       "  'of',\n",
       "  'AWB',\n",
       "  'kickbacks',\n",
       "  'The',\n",
       "  'Prime',\n",
       "  'Minister',\n",
       "  'has',\n",
       "  'denied',\n",
       "  'he',\n",
       "  'knew',\n",
       "  'AWB',\n",
       "  'was',\n",
       "  'paying',\n",
       "  'kickbacks',\n",
       "  'to',\n",
       "  'Iraq',\n",
       "  'despite',\n",
       "  'writing',\n",
       "  'to',\n",
       "  'the',\n",
       "  'wheat',\n",
       "  'exporter',\n",
       "  'asking',\n",
       "  'to',\n",
       "  'be',\n",
       "  'kept',\n",
       "  'fully',\n",
       "  'informed',\n",
       "  'on',\n",
       "  'Iraq',\n",
       "  'wheat',\n",
       "  'sales',\n",
       "  '.'],\n",
       " ['Letters',\n",
       "  'from',\n",
       "  'John',\n",
       "  'Howard',\n",
       "  'and',\n",
       "  'Deputy',\n",
       "  'Prime',\n",
       "  'Minister',\n",
       "  'Mark',\n",
       "  'Vaile',\n",
       "  'to',\n",
       "  'AWB',\n",
       "  'have',\n",
       "  'been',\n",
       "  'released',\n",
       "  'by',\n",
       "  'the',\n",
       "  'Cole',\n",
       "  'inquiry',\n",
       "  'into',\n",
       "  'the',\n",
       "  'oil',\n",
       "  'for',\n",
       "  'food',\n",
       "  'program',\n",
       "  '.'],\n",
       " ['In',\n",
       "  'one',\n",
       "  'of',\n",
       "  'the',\n",
       "  'letters',\n",
       "  'Mr',\n",
       "  'Howard',\n",
       "  'asks',\n",
       "  'AWB',\n",
       "  'managing',\n",
       "  'director',\n",
       "  'Andrew',\n",
       "  'Lindberg',\n",
       "  'to',\n",
       "  'remain',\n",
       "  'in',\n",
       "  'close',\n",
       "  'contact',\n",
       "  'with',\n",
       "  'the',\n",
       "  'Government',\n",
       "  'on',\n",
       "  'Iraq',\n",
       "  'wheat',\n",
       "  'sales',\n",
       "  '.']]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6971d18f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29059"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "455e5c5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "05f9e54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec(sentences=corpus,vector_size=100,window=5,min_count=5,workers=4,sg=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "58ab7ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('woman', 0.9233418107032776), ('skull', 0.911030113697052), ('Bang', 0.905648946762085), ('asteroid', 0.9052114486694336), ('third', 0.9020071625709534), ('baby', 0.8994219303131104), ('dog', 0.898607611656189), ('bought', 0.8975202441215515), ('rally', 0.8912495374679565), ('disc', 0.8889137506484985)]\n"
     ]
    }
   ],
   "source": [
    "model_result = model.wv.most_similar('man')\n",
    "print(model_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "65c86509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model load complete\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "model.wv.save_word2vec_format('./word_embedding/w2v')\n",
    "loaded_model = KeyedVectors.load_word2vec_format(\"./word_embedding/w2v\")\n",
    "print(\"model load complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bcc1da74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('woman', 0.9233418107032776), ('skull', 0.911030113697052), ('Bang', 0.905648946762085), ('asteroid', 0.9052114486694336), ('third', 0.9020071625709534), ('baby', 0.8994219303131104), ('dog', 0.898607611656189), ('bought', 0.8975202441215515), ('rally', 0.8912495374679565), ('disc', 0.8889137506484985)]\n"
     ]
    }
   ],
   "source": [
    "model_result = loaded_model.most_similar('man')\n",
    "print(model_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8c120713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('woman', 0.9233418107032776),\n",
       " ('skull', 0.911030113697052),\n",
       " ('Bang', 0.905648946762085),\n",
       " ('asteroid', 0.9052114486694336),\n",
       " ('third', 0.9020071625709534),\n",
       " ('baby', 0.8994219303131104),\n",
       " ('dog', 0.898607611656189),\n",
       " ('bought', 0.8975202441215515),\n",
       " ('rally', 0.8912495374679565),\n",
       " ('disc', 0.8889137506484985)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 에러가 나더라도 놀라지 마세요.\n",
    "loaded_model.most_similar('man')\n",
    "#KeyError: \"Key 'overacting' not present\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5356072f",
   "metadata": {},
   "source": [
    "# 5-8. 임베딩 벡터의 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7211d694",
   "metadata": {},
   "source": [
    "# 5-9. FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4981fcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "fasttext_model = FastText(corpus,window=5,min_count=5,workers=4,sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f7c3953c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fluctuating', 0.9416335821151733),\n",
       " ('resolving', 0.940483033657074),\n",
       " ('emptying', 0.9352311491966248),\n",
       " ('malting', 0.9350288510322571),\n",
       " ('shooting', 0.9328505396842957),\n",
       " ('overwhelming', 0.932068407535553),\n",
       " ('mounting', 0.9305345416069031),\n",
       " ('debilitating', 0.9301708936691284),\n",
       " ('extracting', 0.9295319318771362),\n",
       " ('declining', 0.9280957579612732)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasttext_model.wv.most_similar('overacting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0621ef6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('memory', 0.946443498134613),\n",
       " ('musical', 0.865608811378479),\n",
       " ('basic', 0.8654351234436035),\n",
       " ('mechanisms', 0.8645912408828735),\n",
       " ('mechanism', 0.8621349930763245),\n",
       " ('mechanical', 0.8546159863471985),\n",
       " ('imagine', 0.8526882529258728),\n",
       " ('technical', 0.8464776277542114),\n",
       " ('intelligence', 0.8410244584083557),\n",
       " ('duplicate', 0.8382733464241028)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasttext_model.wv.most_similar('memoryy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62195507",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

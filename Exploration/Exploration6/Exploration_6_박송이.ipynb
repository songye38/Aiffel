{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2. 데이터 읽어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 크기 :  187088\n",
      "Examples :\n",
      " ['', '', 'All of this and more is for you']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "txt_file_path = './data/lyrics/*'\n",
    "txt_list = glob.glob(txt_file_path)\n",
    "raw_corpus = []\n",
    "\n",
    "for txt_file in txt_list:\n",
    "    with open(txt_file,\"r\") as f:\n",
    "        raw = f.read().splitlines()\n",
    "        raw_corpus.extend(raw)\n",
    "\n",
    "print(\"데이터 크기 : \",len(raw_corpus))\n",
    "print(\"Examples :\\n\",raw_corpus[:3])        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3. 데이터 정제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-1)정규표현식을 이용한 corpus 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip() # 1\n",
    "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence) # 2\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence) # 3\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence) # 4\n",
    "    sentence = sentence.strip() # 5\n",
    "    sentence = '<start> ' + sentence + ' <end>' # 6\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "187088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 187088/187088 [00:15<00:00, 12002.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "print(\"------\")\n",
    "print(len(raw_corpus))\n",
    "filtered_corpus = []\n",
    "\n",
    "for sentence in tqdm(raw_corpus):\n",
    "    if len(sentence)==0: continue\n",
    "    \n",
    "    preprocessd_sentence = preprocess_sentence(sentence)\n",
    "    if len(preprocessd_sentence) < 130:\n",
    "        filtered_corpus.append(preprocessd_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101444"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#필요없는 부분\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "new_list = []\n",
    "#토큰의 개수가 15개가 넘는 문장들은 삭제하기 위해 문장들의 길이 파악\n",
    "for i in range(len(filtered_corpus)):\n",
    "    new_list.append(len(filtered_corpus[i]))\n",
    "    \n",
    "df['length_of_corpus'] = pd.DataFrame(new_list)\n",
    "df = df[df['length_of_corpus'] < ]\n",
    "plt.plot(df)\n",
    "len(df)\n",
    "#print(\"Length of each corpus :\\n\",len(raw_corpus))\n",
    "#토큰화를 해보고 나서 너무 긴 문장들은 삭제하는 함수를 써주자. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2) 코퍼스를 텐서로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(corpus):\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "        num_words = 12000,\n",
    "        filters = ' ', #필터링은 이미 했음.\n",
    "        oov_token = \"<unk>\"\n",
    "    )\n",
    "    tokenizer.fit_on_texts(corpus) #문자 데이터를 입력받아 리스트 형태로 리턴 \n",
    "    tensor = tokenizer.texts_to_sequences(corpus) #텍스트 안의 단어들을 숫자의 시퀀스로 변환\n",
    "    \n",
    "    #입력데이터의 시퀀스 길이를 일정하게 맞춰준다.\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,padding='post',maxlen=10)\n",
    "    #print(tensor,tokenizer)\n",
    "    return tensor,tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor,tokenizer = tokenize(filtered_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2 24 19 42  8 98 26 28  7  3]\n"
     ]
    }
   ],
   "source": [
    "print(tensor[0])  \n",
    "#maxlen = 10 len(tensor)= 175232\n",
    "#maxlen = 20 len(tensor)= 175232\n",
    "#maxlen = 5 len(tensor)= 175232\n",
    "#maxlen = 15 len(tensor)= 175232\n",
    "#왜 maxlen을 바꿔도 텐서의 양은 같은지?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in tokenizer.index_word:\n",
    "    print(idx, \":\",tokenizer.index_word[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "지우기전의 tensor 개수  :  134615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 134615/134615 [00:02<00:00, 67206.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "지우고 난 후 tensor 개수  :  993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#필요없는 부분\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"지우기전의 tensor 개수  : \",len(tensor))\n",
    "num = 0\n",
    "for i in tqdm(range(len(tensor))):\n",
    "    if len(np.nonzero(tensor[i])[0]) >=15:\n",
    "        num+=1\n",
    "\n",
    "    \n",
    "print(\"지우고 난 후 tensor 개수  : \",num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2 14 33  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "print(tensor[50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-3) corpus 텐서를 tf.data.Dataset객체로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_input = tensor[:,:-1]\n",
    "tgt_input = tensor[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((256, 21), (256, 21)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BUFFER_SIZE = len(src_input)\n",
    "BATCH_SIZE = 256\n",
    "steps_per_epoch = len(src_input) // BATCH_SIZE\n",
    "\n",
    "VOCAB_SIZE = tokenizer.num_words +1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((src_input,tgt_input))\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE,drop_remainder=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4. 평가 데이터셋 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = tensor[:,:-1]\n",
    "y = tensor[:,1:]\n",
    "enc_train, enc_val, dec_train, dec_val = train_test_split(X,y,test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5. 인공지능 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerator(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "        super().__init__()\n",
    "        # Embedding 레이어, 2개의 LSTM 레이어, 1개의 Dense 레이어로 구성되어 있다.\n",
    "        # Embedding 레이어는 단어 사전의 인덱스 값을 해당 인덱스 번째의 워드 벡터로 바꿔준다.\n",
    "        # 이 워드 벡터는 의미 벡터 공간에서 단어의 추상적 표현으로 사용된다. \n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size) \n",
    "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)  \n",
    "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.rnn_1(out)\n",
    "        out = self.rnn_2(out)\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 256\n",
    "hidden_size = 1024\n",
    "model = TextGenerator(tokenizer.num_words+1, embedding_size,hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(256, 21, 12001), dtype=float32, numpy=\n",
       "array([[[-1.21119730e-04, -1.19738885e-04,  1.70891144e-05, ...,\n",
       "         -6.23908854e-05,  4.93881467e-04, -1.88387367e-05],\n",
       "        [-5.13922889e-04, -3.59182392e-04,  7.76134257e-05, ...,\n",
       "         -2.52882339e-04,  6.29051123e-04,  5.63973772e-05],\n",
       "        [-6.62973442e-04, -4.80086019e-04,  2.25280673e-04, ...,\n",
       "         -3.27938615e-04,  8.52526224e-04, -8.08773402e-05],\n",
       "        ...,\n",
       "        [ 3.57690989e-03,  2.19079480e-03, -6.19052094e-04, ...,\n",
       "         -3.95590393e-03, -1.06324803e-03, -1.46384339e-03],\n",
       "        [ 3.72518622e-03,  2.12947186e-03, -7.10590219e-04, ...,\n",
       "         -3.97755671e-03, -1.04609784e-03, -1.43377075e-03],\n",
       "        [ 3.85128707e-03,  2.06276379e-03, -7.91124592e-04, ...,\n",
       "         -3.98900406e-03, -1.02527882e-03, -1.40316633e-03]],\n",
       "\n",
       "       [[-1.21119730e-04, -1.19738885e-04,  1.70891144e-05, ...,\n",
       "         -6.23908854e-05,  4.93881467e-04, -1.88387367e-05],\n",
       "        [-1.51312124e-05,  8.52534577e-05,  6.30164286e-05, ...,\n",
       "         -6.61510567e-05,  7.65319681e-04, -1.43780679e-04],\n",
       "        [ 1.32959351e-04, -1.57732939e-06,  6.89097069e-05, ...,\n",
       "         -3.05642170e-05,  6.52022485e-04, -1.95099783e-04],\n",
       "        ...,\n",
       "        [ 2.29166518e-03,  1.83562236e-03, -6.61581871e-05, ...,\n",
       "         -3.57529754e-03, -1.38587411e-03, -1.48007669e-03],\n",
       "        [ 2.57229176e-03,  1.96237070e-03, -1.99461239e-04, ...,\n",
       "         -3.70920543e-03, -1.41905167e-03, -1.53181260e-03],\n",
       "        [ 2.83019221e-03,  2.04665517e-03, -3.29403323e-04, ...,\n",
       "         -3.80920153e-03, -1.42449897e-03, -1.56068511e-03]],\n",
       "\n",
       "       [[-1.21119730e-04, -1.19738885e-04,  1.70891144e-05, ...,\n",
       "         -6.23908854e-05,  4.93881467e-04, -1.88387367e-05],\n",
       "        [-4.44921112e-04, -3.64156382e-04, -1.00808757e-05, ...,\n",
       "         -1.31138746e-04,  7.26296334e-04,  1.63717908e-04],\n",
       "        [-4.37397946e-04, -6.55397074e-04, -8.70255826e-05, ...,\n",
       "          1.72171291e-04,  5.97787206e-04,  2.46787677e-04],\n",
       "        ...,\n",
       "        [ 1.81396643e-03,  2.26303400e-03,  6.16216566e-04, ...,\n",
       "         -3.74565087e-03, -1.14265480e-03, -1.62109267e-03],\n",
       "        [ 2.17010756e-03,  2.31727539e-03,  4.01164521e-04, ...,\n",
       "         -3.91877536e-03, -1.18251808e-03, -1.61515840e-03],\n",
       "        [ 2.49000546e-03,  2.33339518e-03,  1.95604225e-04, ...,\n",
       "         -4.04230086e-03, -1.20129972e-03, -1.59440888e-03]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-1.21119730e-04, -1.19738885e-04,  1.70891144e-05, ...,\n",
       "         -6.23908854e-05,  4.93881467e-04, -1.88387367e-05],\n",
       "        [-4.95969667e-04, -3.75049189e-04,  3.12438322e-04, ...,\n",
       "         -2.11234030e-04,  7.03772646e-04, -6.54435280e-05],\n",
       "        [-6.05608977e-04, -5.35724510e-04,  4.34935675e-04, ...,\n",
       "         -3.76549549e-04,  6.84691942e-04, -2.14939093e-04],\n",
       "        ...,\n",
       "        [ 2.32991832e-03,  2.14958028e-03, -1.94609340e-04, ...,\n",
       "         -3.68202338e-03, -6.18581544e-04, -1.64924795e-03],\n",
       "        [ 2.58442527e-03,  2.27054511e-03, -2.78826541e-04, ...,\n",
       "         -3.83271673e-03, -7.20879179e-04, -1.67820405e-03],\n",
       "        [ 2.82360264e-03,  2.34507490e-03, -3.68387060e-04, ...,\n",
       "         -3.94264236e-03, -7.98522902e-04, -1.68595021e-03]],\n",
       "\n",
       "       [[-1.21119730e-04, -1.19738885e-04,  1.70891144e-05, ...,\n",
       "         -6.23908854e-05,  4.93881467e-04, -1.88387367e-05],\n",
       "        [-1.27239327e-04, -2.25925774e-04, -1.96468027e-05, ...,\n",
       "         -4.07889718e-04,  7.76360277e-04,  1.42192393e-05],\n",
       "        [-4.06826730e-05, -1.76674221e-04, -1.06041029e-04, ...,\n",
       "         -5.23568247e-04,  9.43182909e-04,  1.36410061e-04],\n",
       "        ...,\n",
       "        [ 2.16777902e-03,  1.99489878e-03,  1.79139897e-04, ...,\n",
       "         -3.34409298e-03, -1.01430598e-03, -8.04974814e-04],\n",
       "        [ 2.46975082e-03,  2.07082182e-03,  3.89626948e-05, ...,\n",
       "         -3.54455505e-03, -1.08291279e-03, -9.27464105e-04],\n",
       "        [ 2.74180132e-03,  2.10873364e-03, -1.04173378e-04, ...,\n",
       "         -3.69671895e-03, -1.12663303e-03, -1.02300826e-03]],\n",
       "\n",
       "       [[-1.21119730e-04, -1.19738885e-04,  1.70891144e-05, ...,\n",
       "         -6.23908854e-05,  4.93881467e-04, -1.88387367e-05],\n",
       "        [-8.35190003e-05, -4.79975351e-05, -7.74080909e-05, ...,\n",
       "         -1.00614998e-04,  4.81796043e-04, -3.03782581e-04],\n",
       "        [-1.59534247e-04, -1.30623637e-04, -2.14387823e-04, ...,\n",
       "         -9.28824447e-05,  7.06703635e-04, -4.27782128e-04],\n",
       "        ...,\n",
       "        [ 3.56359174e-03,  2.28101923e-03, -3.55363707e-04, ...,\n",
       "         -3.78533266e-03, -9.15921526e-04, -1.51770632e-03],\n",
       "        [ 3.70055716e-03,  2.22912244e-03, -4.76731046e-04, ...,\n",
       "         -3.83877521e-03, -9.42769810e-04, -1.49641407e-03],\n",
       "        [ 3.81926703e-03,  2.16725841e-03, -5.87083632e-04, ...,\n",
       "         -3.87705117e-03, -9.56914504e-04, -1.46895996e-03]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for src_sample, tgt_sample in dataset.take(1): break\n",
    "    \n",
    "model(src_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"text_generator_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      multiple                  3072256   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                multiple                  5246976   \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                multiple                  8392704   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  12301025  \n",
      "=================================================================\n",
      "Total params: 29,012,961\n",
      "Trainable params: 29,012,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam() # Adam은 현재 가장 많이 사용하는 옵티마이저이다. 자세한 내용은 차차 배운다.\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy( # 훈련 데이터의 라벨이 정수의 형태로 제공될 때 사용하는 손실함수이다.\n",
    "    from_logits=True, # 기본값은 False이다. 모델에 의해 생성된 출력 값이 정규화되지 않았음을 손실 함수에 알려준다. 즉 softmax함수가 적용되지 않았다는걸 의미한다. \n",
    "    reduction='none'  # 기본값은 SUM이다. 각자 나오는 값의 반환 원할 때 None을 사용한다.\n",
    ")\n",
    "# 모델을 학습시키키 위한 학습과정을 설정하는 단계이다.\n",
    "model.compile(optimizer=optimizer, loss=loss) # 손실함수와 훈련과정을 설정했다.\n",
    "model.fit(dataset,epochs=10) # 만들어둔 데이터셋으로 모델을 학습한다. 30번 학습을 반복하겠다는 의미다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#로컬 컴퓨터가 너무 느려서 lms상에서 돌렸어요.\n",
    "#우선 결과는 붙여넣기 할게요. \n",
    "##13000개 정도 tensor를 가지고 한 결과 \n",
    "Epoch 1/10\n",
    "525/525 [==============================] - 134s 251ms/step - loss: 2.1619\n",
    "Epoch 2/10\n",
    "525/525 [==============================] - 137s 260ms/step - loss: 1.8200\n",
    "Epoch 3/10\n",
    "525/525 [==============================] - 136s 259ms/step - loss: 1.7123\n",
    "Epoch 4/10\n",
    "525/525 [==============================] - 136s 259ms/step - loss: 1.6304\n",
    "Epoch 5/10\n",
    "525/525 [==============================] - 136s 259ms/step - loss: 1.5593\n",
    "Epoch 6/10\n",
    "525/525 [==============================] - 136s 259ms/step - loss: 1.4944\n",
    "Epoch 7/10\n",
    "525/525 [==============================] - 136s 259ms/step - loss: 1.4348\n",
    "Epoch 8/10\n",
    "525/525 [==============================] - 137s 260ms/step - loss: 1.3797\n",
    "Epoch 9/10\n",
    "525/525 [==============================] - 137s 260ms/step - loss: 1.3283\n",
    "Epoch 10/10\n",
    "525/525 [==============================] - 136s 260ms/step - loss: 1.2802"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'<start> i love -> '<start> i love you , i m a fool <end> '\n",
    "'<start> you are -> '<start> you are the greatest <end> '\n",
    "'<start> always -> '<start> always , i m the one <end> '\n",
    "'<start> you are -> '<start> you re the only one who knows that <end> '\n",
    "'<start> sky ->'<start> sky is the limit and you know that you can have <end> '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam() # Adam은 현재 가장 많이 사용하는 옵티마이저이다. 자세한 내용은 차차 배운다.\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy( # 훈련 데이터의 라벨이 정수의 형태로 제공될 때 사용하는 손실함수이다.\n",
    "    from_logits=True, # 기본값은 False이다. 모델에 의해 생성된 출력 값이 정규화되지 않았음을 손실 함수에 알려준다. 즉 softmax함수가 적용되지 않았다는걸 의미한다. \n",
    "    reduction='none'  # 기본값은 SUM이다. 각자 나오는 값의 반환 원할 때 None을 사용한다.\n",
    ")\n",
    "# 모델을 학습시키키 위한 학습과정을 설정하는 단계이다.\n",
    "model.compile(optimizer=optimizer, loss=loss) # 손실함수와 훈련과정을 설정했다.\n",
    "model.fit(enc_train,dec_train,epochs=10) # 만들어둔 데이터셋으로 모델을 학습한다. 30번 학습을 반복하겠다는 의미다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#175232개 정도 tensor를 가지고 한 결과 \n",
    "Epoch 1/10\n",
    "3366/3366 [==============================] - 157s 46ms/step - loss: 1.3962\n",
    "Epoch 2/10\n",
    "3366/3366 [==============================] - 153s 45ms/step - loss: 1.2438\n",
    "Epoch 3/10\n",
    "3366/3366 [==============================] - 153s 45ms/step - loss: 1.1475\n",
    "Epoch 4/10\n",
    "3366/3366 [==============================] - 152s 45ms/step - loss: 1.0684\n",
    "Epoch 5/10\n",
    "3366/3366 [==============================] - 152s 45ms/step - loss: 0.9996\n",
    "Epoch 6/10\n",
    "3366/3366 [==============================] - 151s 45ms/step - loss: 0.9387\n",
    "Epoch 7/10\n",
    "3366/3366 [==============================] - 152s 45ms/step - loss: 0.8846\n",
    "Epoch 8/10\n",
    "3366/3366 [==============================] - 151s 45ms/step - loss: 0.8365\n",
    "Epoch 9/10\n",
    "3366/3366 [==============================] - 151s 45ms/step - loss: 0.7947\n",
    "Epoch 10/10\n",
    "3366/3366 [==============================] - 151s 45ms/step - loss: 0.7590"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'<start> i love ->'<start> i love you so <end> '\n",
    "'<start> you are ->'<start> you are the lady in my life <end> '\n",
    "'<start> always ->'<start> always <end> '\n",
    "'<start> you are ->'<start> you are the lady in my life <end> '\n",
    "'<start> sky ->'<start> sky is the limit and you know that you can have <end> '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#maxlen을 20으로 한 결과\n",
    "Epoch 1/10\n",
    "687/687 [==============================] - 151s 216ms/step - loss: 2.8733\n",
    "Epoch 2/10\n",
    "687/687 [==============================] - 161s 234ms/step - loss: 2.4726\n",
    "Epoch 3/10\n",
    "687/687 [==============================] - 163s 238ms/step - loss: 2.3140\n",
    "Epoch 4/10\n",
    "687/687 [==============================] - 164s 238ms/step - loss: 2.1969\n",
    "Epoch 5/10\n",
    "687/687 [==============================] - 164s 238ms/step - loss: 2.0994\n",
    "Epoch 6/10\n",
    "687/687 [==============================] - 164s 238ms/step - loss: 2.0119\n",
    "Epoch 7/10\n",
    "687/687 [==============================] - 164s 238ms/step - loss: 1.9304\n",
    "Epoch 8/10\n",
    "687/687 [==============================] - 164s 238ms/step - loss: 1.8543\n",
    "Epoch 9/10\n",
    "687/687 [==============================] - 164s 238ms/step - loss: 1.7825\n",
    "Epoch 10/10\n",
    "687/687 [==============================] - 164s 238ms/step - loss: 1.7146"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'<start> i love ->'<start> i love you , i m not gonna crack <end> '\n",
    "'<start> you are ->'<start> you are the only one who knows that i m so glad <end> '\n",
    "'<start> always ->'<start> always , baby , no <end> '\n",
    "'<start> sky ->'<start> sky is the limit and you know that you can have <end> '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#결과 4 maxlen=15로 조정한 결과\n",
    "tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,padding='post',maxlen=15)\n",
    "Epoch 1/10\n",
    "684/684 [==============================] - 74s 101ms/step - loss: 4.6258\n",
    "Epoch 2/10\n",
    "684/684 [==============================] - 74s 107ms/step - loss: 3.9809\n",
    "Epoch 3/10\n",
    "684/684 [==============================] - 77s 112ms/step - loss: 3.7159\n",
    "Epoch 4/10\n",
    "684/684 [==============================] - 77s 112ms/step - loss: 3.5053\n",
    "Epoch 5/10\n",
    "684/684 [==============================] - 76s 111ms/step - loss: 3.3123\n",
    "Epoch 6/10\n",
    "684/684 [==============================] - 77s 112ms/step - loss: 3.1274\n",
    "Epoch 7/10\n",
    "684/684 [==============================] - 77s 112ms/step - loss: 2.9479\n",
    "Epoch 8/10\n",
    "684/684 [==============================] - 76s 112ms/step - loss: 2.7742\n",
    "Epoch 9/10\n",
    "684/684 [==============================] - 77s 112ms/step - loss: 2.6038\n",
    "Epoch 10/10\n",
    "684/684 [==============================] - 77s 112ms/step - loss: 2.4391"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'<start> i love ->'<start> i love you <end> '\n",
    "'<start> you are ->'<start> you are my <unk> <end> '\n",
    "'<start> always ->'<start> always <end> '\n",
    "'<start> sky ->'<start> sky and richard <end> '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embedding_size = 512 & hidden_size = 1024\n",
    "Epoch 1/10\n",
    "684/684 [==============================] - 120s 169ms/step - loss: 3.5530\n",
    "Epoch 2/10\n",
    "684/684 [==============================] - 120s 176ms/step - loss: 3.0496\n",
    "Epoch 3/10\n",
    "684/684 [==============================] - 121s 177ms/step - loss: 2.8478\n",
    "Epoch 4/10\n",
    "684/684 [==============================] - 121s 176ms/step - loss: 2.6898\n",
    "Epoch 5/10\n",
    "684/684 [==============================] - 121s 177ms/step - loss: 2.5495\n",
    "Epoch 6/10\n",
    "684/684 [==============================] - 121s 177ms/step - loss: 2.4198\n",
    "Epoch 7/10\n",
    "684/684 [==============================] - 121s 177ms/step - loss: 2.2988\n",
    "Epoch 8/10\n",
    "684/684 [==============================] - 241s 352ms/step - loss: 2.1831\n",
    "Epoch 9/10\n",
    "684/684 [==============================] - 255s 372ms/step - loss: 2.0723\n",
    "Epoch 10/10\n",
    "684/684 [==============================] - 259s 378ms/step - loss: 1.9669"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'<start> i love ->'<start> i love you , liberian girl <end> '\n",
    "'<start> you are ->'<start> you are the only one <end> '\n",
    "'<start> always ->'<start> always searching for a minute <end> '\n",
    "'<start> sky ->'<start> sky is the limit and you know that you can have <end> '\n",
    "#표현의 풍부함을 평가할 수는 없을까? \n",
    "#정확도, 재현율 등등으로는 글을 평가할 수 없을 것 같은데?\n",
    "#참신함을 평가할 순 없을까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embedding_size = 256 & hidden_size = 512\n",
    "Epoch 1/10\n",
    "684/684 [==============================] - 91s 130ms/step - loss: 3.9067\n",
    "Epoch 2/10\n",
    "684/684 [==============================] - 108s 158ms/step - loss: 3.3920\n",
    "Epoch 3/10\n",
    "684/684 [==============================] - 108s 158ms/step - loss: 3.1702\n",
    "Epoch 4/10\n",
    "684/684 [==============================] - 108s 158ms/step - loss: 3.0441\n",
    "Epoch 5/10\n",
    "684/684 [==============================] - 109s 158ms/step - loss: 2.9414\n",
    "Epoch 6/10\n",
    "684/684 [==============================] - 109s 159ms/step - loss: 2.8537\n",
    "Epoch 7/10\n",
    "684/684 [==============================] - 108s 158ms/step - loss: 2.7765\n",
    "Epoch 8/10\n",
    "684/684 [==============================] - 109s 159ms/step - loss: 2.7045\n",
    "Epoch 9/10\n",
    "684/684 [==============================] - 109s 158ms/step - loss: 2.6345\n",
    "Epoch 10/10\n",
    "684/684 [==============================] - 109s 159ms/step - loss: 2.5639"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'<start> i love ->'<start> i love you , i love you <end> '\n",
    "'<start> you are ->'<start> you are the one <end> '\n",
    "'<start> always ->'<start> always in the world <end> '\n",
    "'<start> sky ->'<start> sky is the limit and you know that you can do <end> '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embedding_size = 128 & hidden_size = 512\n",
    "Epoch 1/10\n",
    "684/684 [==============================] - 49s 68ms/step - loss: 3.9435\n",
    "Epoch 2/10\n",
    "684/684 [==============================] - 46s 67ms/step - loss: 3.3453\n",
    "Epoch 3/10\n",
    "684/684 [==============================] - 47s 68ms/step - loss: 3.1801\n",
    "Epoch 4/10\n",
    "684/684 [==============================] - 47s 68ms/step - loss: 3.0672\n",
    "Epoch 5/10\n",
    "684/684 [==============================] - 47s 68ms/step - loss: 2.9746\n",
    "Epoch 6/10\n",
    "684/684 [==============================] - 47s 68ms/step - loss: 2.8973\n",
    "Epoch 7/10\n",
    "684/684 [==============================] - 47s 68ms/step - loss: 2.8312\n",
    "Epoch 8/10\n",
    "684/684 [==============================] - 47s 68ms/step - loss: 2.7715\n",
    "Epoch 9/10\n",
    "684/684 [==============================] - 47s 68ms/step - loss: 2.7151\n",
    "Epoch 10/10\n",
    "684/684 [==============================] - 47s 68ms/step - loss: 2.6586"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'<start> i love ->'<start> i love you , i m a <unk> <end> '\n",
    "'<start> you are ->'<start> you are the one <end> '\n",
    "'<start> always ->'<start> always <unk> <end> '\n",
    "'<start> sky ->'<start> sky is the limit and you know that you re gonna <end> '"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695ff2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "\n",
    "import PIL\n",
    "import imageio\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "cifar10 = tf.keras.datasets.cifar10\n",
    "\n",
    "def load_data(label=None):\n",
    "    (train_x, train_y), (test_x, test_y) = tf.keras.datasets.cifar10.load_data()\n",
    "    if label:\n",
    "        df = pd.DataFrame(list(zip(train_x, train_y)), columns=['image', 'label']) \n",
    "        df = df[df['label']==label]\n",
    "        train_x = np.array([i for i in list(df['image'])])\n",
    "        df = pd.DataFrame(list(zip(test_x, test_y)), columns =['image', 'label']) \n",
    "        df = df[df['label']==label]\n",
    "        test_x = np.array([i for i in list(df['image'])])\n",
    "    return train_x, test_x\n",
    "\n",
    "#train_x 50,000장 test_x 10,000장으로 이루어져 있음.\n",
    "train_x,test_x = load_data()\n",
    "train_x.shape\n",
    "\n",
    "print(\"step1 데이터 가져오기 완료!\")\n",
    "\n",
    "train_x = (train_x - 127.5) / 127.5\n",
    "BUFFER_SIZE = 50000\n",
    "BATCH_SIZE = 256\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_x).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "print(\"step2 데이터 전처리 완료!\")\n",
    "\n",
    "def make_generator_model():\n",
    "\n",
    "    # Start\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    # First: Dense layer\n",
    "    model.add(layers.Dense(8*8*256, use_bias=False, input_shape=(100,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    # Second: Reshape layer\n",
    "    model.add(layers.Reshape((8, 8, 256)))\n",
    "\n",
    "    # Third: Conv2DTranspose layer\n",
    "    model.add(layers.Conv2DTranspose(128, kernel_size=(5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    # Fourth: Conv2DTranspose layer\n",
    "    model.add(layers.Conv2DTranspose(64, kernel_size=(5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    # Fifth: Conv2DTranspose layer\n",
    "    model.add(layers.Conv2DTranspose(3, kernel_size=(5, 5), strides=(2, 2), padding='same', use_bias=False, \\\n",
    "                                     activation='tanh'))\n",
    "\n",
    "    return model\n",
    "\n",
    "generator = make_generator_model()\n",
    "generator.summary()\n",
    "print(\"step3 생성자 모델 구현 완료!\")\n",
    "\n",
    "def make_discriminator_model():\n",
    "\n",
    "    # Start\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    # First: Conv2D Layer\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[32, 32, 3]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    # Second: Conv2D Layer\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    # Third: Flatten Layer\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    # Fourth: Dense Layer\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    return model\n",
    "\n",
    "discriminator = make_discriminator_model()\n",
    "discriminator.summary()\n",
    "print(\"step4 판별자 모델 구현 완료!\")\n",
    "\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output),fake_output)\n",
    "    \n",
    "def discriminator_loss(real_output,fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output),real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output),fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss \n",
    "\n",
    "def discriminator_accuracy(real_output,fake_output):\n",
    "    real_accuracy = tf.reduce_mean(tf.cast(tf.math.greater_equal(real_output, tf.constant([0.5])), tf.float32))\n",
    "    fake_accuracy = tf.reduce_mean(tf.cast(tf.math.less(fake_output, tf.constant([0.5])), tf.float32))\n",
    "    return real_accuracy, fake_accuracy\n",
    "\n",
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "noise_dim = 100\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])\n",
    "seed.shape\n",
    "\n",
    "print(\"step5 손실함수 최적화 함수 구현 완료!\")\n",
    "\n",
    "\n",
    "def train_step(images):\n",
    "    #1. 노이즈를 생성해준다.\n",
    "    noise = tf.random.normal([BATCH_SIZE,noise_dim])\n",
    "    #2. 미분을 계산할 수 있는 그라디언트 테이프를 생성자, 판별자용으로 2개 만든다.\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        #3. 그 안에서 계산을 해준다. \n",
    "        #4. 위에서 만든 노이즈를 가지고 생성자로 이미지를 만든다. \n",
    "        generated_images = generator(noise,training=True)\n",
    "        #5. 판별자로 판별한다. \n",
    "        real_output= discriminator(images,training=True)\n",
    "        fake_output = discriminator(generated_images,training=True)\n",
    "    #6. loss 계산한다.\n",
    "        gen_loss =  generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output,fake_output)\n",
    "    #7. accuracy 계산한다. \n",
    "        real_accuracy, fake_accuracy = discriminator_accuracy(real_output,fake_output)\n",
    "    #8. 미분을 계산해야 할 것들의 계산이 끝난다. \n",
    "    #9. gradient를 생성자,판별자 각각 계산한다. \n",
    "        gen_graident = gen_tape.gradient(gen_loss,generator.trainable_variables)\n",
    "        disc_gradient = disc_tape.gradient(disc_loss,discriminator.trainable_variables)\n",
    "    #10. 각각의 옵티마이저에 그라디언트를 적용한다. \n",
    "        generator_optimizer.apply_gradients(zip(gen_graident,generator.trainable_variables))\n",
    "        discriminator_optimizer.apply_gradients(zip(disc_gradient,discriminator.trainable_variables))\n",
    "    #11. 생성자와 판별자의 loss, accuracy를 리턴한다. \n",
    "        return gen_loss,disc_loss,real_accuracy,fake_accuracy\n",
    "    \n",
    "def generate_and_save_images(model,epoch,it,sample_seeds):\n",
    "    #1. 모델을 통해 샘플을 prediction을 하나 만든다. \n",
    "    predictions = model(sample_seeds,training=False)\n",
    "    #2. 4,4 subplot으로 이미지 그려주기\n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(4,4,i+1)\n",
    "        plt.imshow(predictions[i,:,:,0],cmap='gray')\n",
    "        plt.axis('off')\n",
    "    #3. savefig를 통해 그렇게 만들어진 이미지를 저장해주기 \n",
    "    plt.savefig('{}/aiffel/dcgan_newimage/cifar10/generated_samples/sample_epoch_{:04d}_iter_{:03d}.png'\n",
    "                    .format(os.getenv('HOME'), epoch, it))\n",
    "    plt.show()\n",
    "    \n",
    "def draw_train_history(history,epoch):\n",
    "    #1. loss 그려주기\n",
    "    plt.subplot(211)\n",
    "    plt.plot(history['gen_loss'])\n",
    "    plt.plot(history['disc_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('batch iters')\n",
    "    plt.legend(['gen_loss','disc_loss'],loc='upper left')\n",
    "    \n",
    "    #2. accuracy 그려주기 \n",
    "    plt.subplot(212)\n",
    "    plt.plot(history['fake_accuracy'])\n",
    "    plt.plot(history['real_accuracy'])\n",
    "    plt.title('discriminator accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('batch iters')\n",
    "    plt.legend(['fake_accuracy','real_accuracy'],loc='upper left')\n",
    "    \n",
    "    #3. 저장해주기 \n",
    "    plt.savefig('{}/aiffel/dcgan_newimage/cifar10/training_history/train_history_{:04d}.png'\n",
    "                    .format(os.getenv('HOME'), epoch))\n",
    "    plt.show()\n",
    "    \n",
    "#1. 체크포인트를 저장할 폴더 위치 정해주기\n",
    "checkpoint_dir = os.getenv('HOME')+'/aiffel/dcgan_newimage/cifar10/training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "#2. 옵티마이저 각각, 모델 각각 저장해주기 \n",
    "checkpoints = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator = generator,\n",
    "                                 discriminator=discriminator)\n",
    "\n",
    "print(\"step6 훈련과정 상세 기능 구현 완료!\")\n",
    "\n",
    "def train(dataset, epochs, save_every):\n",
    "    start = time.time()\n",
    "    history = {'gen_loss':[], 'disc_loss':[], 'real_accuracy':[], 'fake_accuracy':[]}\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_start = time.time()\n",
    "        for it, image_batch in enumerate(dataset):\n",
    "            gen_loss, disc_loss, real_accuracy, fake_accuracy = train_step(image_batch)\n",
    "            history['gen_loss'].append(gen_loss)\n",
    "            history['disc_loss'].append(disc_loss)\n",
    "            history['real_accuracy'].append(real_accuracy)\n",
    "            history['fake_accuracy'].append(fake_accuracy)\n",
    "\n",
    "            if it % 50 == 0:\n",
    "                display.clear_output(wait=True)\n",
    "                generate_and_save_images(generator, epoch+1, it+1, seed)\n",
    "                print('Epoch {} | iter {}'.format(epoch+1, it+1))\n",
    "                print('Time for epoch {} : {} sec'.format(epoch+1, int(time.time()-epoch_start)))\n",
    "\n",
    "        if (epoch + 1) % save_every == 0:\n",
    "            checkpoints.save(file_prefix=checkpoint_prefix)\n",
    "\n",
    "        display.clear_output(wait=True)\n",
    "        generate_and_save_images(generator, epochs, it, seed)\n",
    "        print('Time for training : {} sec'.format(int(time.time()-start)))\n",
    "\n",
    "        draw_train_history(history, epoch)\n",
    "        \n",
    "save_every = 5\n",
    "EPOCHS = 50\n",
    "train(train_dataset, EPOCHS, save_every)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
